{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY0ZZRVKx5V0CmgE82oLJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/All4Nothing/pytorch-DL-project/blob/main/Ch01_Pytorch_for_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01. 파이토치를 이용한 딥러닝 소개"
      ],
      "metadata": {
        "id": "QR4DCI7BiU2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 딥러닝 되짚어보기\n",
        "전통적인 머신러닝 기반의 접근법에서는 Feature Engineering이 훈련된 모델의 전반적인 성능에 결정적인 역할을 한다. 그렇지만 딥러닝 모델에서는 특징을 공들여 수동으로 만들 필요가 없다. 딥러닝 모델은 특징을 직접 다루지 않고도 대용량의 데이터를 잘 다루면서 전통적인 머신러닝 모델을 능가할 수 있다.  \n",
        "딥러닝 성능은 반드시 특정 데이터셋 크기에 따라 구분되는 것은 아니다. 그렇지만 데이터셋 크기가 더 커질수록 심층 신경망은 딥러닝이 아닌 모델보다 성능이 우수해진다."
      ],
      "metadata": {
        "id": "f7Rp7nvQkAsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![NN Architectural](https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZoo20042019-1400x2380.png)\n",
        "\n",
        "(https://www.asimovinstitute.org/neural-network-zoo/)"
      ],
      "metadata": {
        "id": "clXZz5fPlbsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch 살펴보기"
      ],
      "metadata": {
        "id": "ZEHzTb5Cpym_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Module"
      ],
      "metadata": {
        "id": "i93mWh06p2wN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torch.nn**  \n",
        "신경망 아키텍처를 구축할 때, 네트워크가 구축되는 기본 특징은 계층 수, 각 계층의 뉴런 수, 그중 학습 가능한 뉴런 등이다.  \n",
        "pytorch nn 모듈을 사용하면 사용자가 자세한 사항을 직접 지정하는 대신 이러한 특징 중 일부를 고수준에서 정의함으로써 신경 아키텍처를 빠르게 인스턴스화 할 수 있다."
      ],
      "metadata": {
        "id": "zpAGIm6Dp5xW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn 모듈을 사용하지 않고 단일 계층 신경망을 초기화 하는 코드\n",
        "\n",
        "\n",
        "```\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# 이 단일 계층 신경망의 입력값은 256차원, 출력은 4차원으로 가정한다.\n",
        "# 따라서 랜덤값으로 채워진 256x4 행렬을 초기화한다.\n",
        "weights = torch.randn(256, 4) / math.sqrt(256)\n",
        "\n",
        "# 가중치를 훈련 가능하게, 즉 256x4 행렬의 숫자가 경사 역전파를 통해 조정될 수 있게 만든다.\n",
        "weights.requires_grad_()\n",
        "\n",
        "# 4차원 출력을 위한 편향값을 더하고 이 편향값도 훈련 가능하게 설정한다.\n",
        "bias = torch.zeros(4, requires_grad = True)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r7xBykdGp8K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn 모듈을 사용하여 단일 계층 신경망 초기화\n",
        "\n",
        "\n",
        "```\n",
        "import torch.nn as nn\n",
        "weights = nn.Linear(256, 4)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_4aiG_sQrMNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn 모듈에는 torch.nn.functional이라는 하위 모듈이 있다. 이 하위 모듈은 torch.nn 모듈 내부의 모든 함수를 포함하며, 이 외 다른 하위 모듈은 모두 클래스다.  \n",
        "**손실 함수, 활성화 함수**, 함수적 방식으로 신경망을 생성하기 위해 사용될 수 있는 풀링, 합성곱, 선형 함수 같은 **신경망 함수**가 모두 이 모듈에 포함된다."
      ],
      "metadata": {
        "id": "4xhWQ45zrdEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn.functional 모듈을 사용한 손실 함수\n",
        "```\n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "loss = loss_func(model(X), y) # model: nn model, X: input, y: target output\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ZJMj9eRAruZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torch.optim**\n",
        "신경망을 훈련시키는 동안, 네트워크의 가중치나 매개변수를 조정하기 위해 오차를 역전파한다. 이 과정을 **최적화(optimization)**라고 한다.  \n",
        "optim 모듈은 딥러닝 모델을 훈련하는 동안 다양한 유형의 최적화 스케줄을 실행하는 것과 관련된 도구와 기능을 모두 포함한다."
      ],
      "metadata": {
        "id": "HWlzvWYRsbSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "최적화 단계를 직접 작성\n",
        "```\n",
        "with torch.no_grad():\n",
        "# 확률적 경사 하강법을 사용해 매개변수 업데이트를 적용한다.\n",
        "  for param in model.parameters(): param -= param.grad * lr\n",
        "  model.zero_grad()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UyK2tsTOs1hG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.optim 모듈을 사용해 훈련 세션 동안 옵티마이저를 정의하면\n",
        "```\n",
        "opt = optim.SGD(model.parameters(), lr=lr)\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```\n",
        "이렇게 쓸 수 있다\n",
        "\n"
      ],
      "metadata": {
        "id": "9ZmxPgpMssbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torch.utils.data**  \n",
        "torch에서 utils.data 모듈을 통해 제공하는 자체 데이터셋과 DatasetLoader 클래스들은 이용하면 직관적인 방법으로 텐서에 대한 이터레이션 및 기타 연산을 수행할 수 있고, 최적화된 텐서 계산으로 높은 성능이 보장되며, 데이터 입출력 오류도 피할 수 있다"
      ],
      "metadata": {
        "id": "NxhMlZGvt0hG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.utils.data.DataLoader를 다음과 같이 사용하면\n",
        "\n",
        "\n",
        "```\n",
        "from torch.utils.data import (TensorDataset, DataLoader)\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = bs)\n",
        "```\n",
        "다음처럼 데이터 배치를 수작업으로 이터레이션 할 필요 없이,\n",
        "```\n",
        "for i in range((n-1)//bs + 1):\n",
        "  x_batch = x_train[start_i:end_i]\n",
        "  y_batch = y_train[start_i:end_i]\n",
        "  pred = model(x_batch)\n",
        "```\n",
        "다음과 같이 간단한 코드만 작성하면 된다.\n",
        "```\n",
        "for x_batch, y_batch in train_loader:\n",
        "  pred = model(x_batch)\n"
      ],
      "metadata": {
        "id": "769JaANMuJzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서 모듈"
      ],
      "metadata": {
        "id": "Y_w3hrEauuNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서는 수학 함수를 연산할 수 있고 GPU를 통해 계산 속도를 높일 수 있는 n차원 배열이며, 딥러닝에 필수적인 계산 그래프와 경사를 기록하는데 사용할 수 있다."
      ],
      "metadata": {
        "id": "M6K8x1QJuv7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서 텐서를 인스턴스화 하는 방법\n",
        "```\n",
        "points = torch.tensor([1.0, 4.0, 2.0, 1.0, 3.0, 5.0])\n",
        "```\n",
        "첫 번째 항목 가져오기\n",
        "```\n",
        "float(points[0])\n",
        "```\n",
        "텐서 모양 확인\n",
        "```\n",
        "points.shape\n",
        "```\n",
        "파이토치에서 텐서는 연속된 메모리에 저장된 숫자 데이터의 1차원 배열의 뷰로 구현된다. 이 배열을 storage instance라 한다. 모든 파이토치 텐서는 다음 예제와 같이 텐서의 기본 storage instance를 출력하기 위해 호출할 수 있는 stoarge 속성을 가지고 있다."
      ],
      "metadata": {
        "id": "fmmr3GPBu3Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])\n",
        "points.storage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrUUWwiIveiz",
        "outputId": "a6b6313f-23b7-4c11-d46e-d6b698c9ebb6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-7a144fe74e5d>:3: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  points.storage()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1.0\n",
              " 4.0\n",
              " 2.0\n",
              " 1.0\n",
              " 3.0\n",
              " 5.0\n",
              "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서가 storage instance의 view라고 하면, 텐서는 그 view를 구현하기 위해 다음 정보를 사용한다.\n",
        "- 크기\n",
        "- 스토리지\n",
        "- 오프셋\n",
        "- 스트라이드(보폭)"
      ],
      "metadata": {
        "id": "GmThYRBVvm2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points.size()\n",
        "# 두 숫자를 곱하면 기반 스토리지 인스턴스의 길이가(여기서는 6) 된다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDZ7fXA2vwaQ",
        "outputId": "6d7936a4-d60d-4482-b6c1-6e8fe7087f70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "points.storage_offset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJeNmeNyv8vu",
        "outputId": "65546791-50e1-4009-904a-759472ac5c76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "오프셋은 storage 배열에서 텐서의 첫 번째 요소의 인덱스를 나타낸다"
      ],
      "metadata": {
        "id": "y1ErZXPDwAL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points[1].storage_offset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu08moPIwDx3",
        "outputId": "8c3effa7-b8e5-445d-ab47-a11693686e56"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "points.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vop01idwG4_",
        "outputId": "7eb61f2e-8838-4f45-e999-e0256039d28e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "stride는 각 차원에 대해, 텐서의 다음 요소로 접근하기 위해 건너뛰어야 할 요소의 개수를 포함하고 있다."
      ],
      "metadata": {
        "id": "igG4yfSxwI1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서에서 사용할 데이터 타입을 지정하는 방법은 다음과 같다."
      ],
      "metadata": {
        "id": "j7HFCGt5wQPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points = torch.tensor([[1.0, 2.0], [3.0, 4.0]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "oyaQ9hQ_wUQf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 타입 외, 파이토치의 텐서는 데이터를 저장할 장치를 지정해야 한다. 장치는 인스턴스화할 때 지정할 수 있다."
      ],
      "metadata": {
        "id": "Fr6BVWFNwc39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points = torch.tensor([[1.0, 2.0], [3.0, 4.0]], dtype=torch.float32, device='cpu')"
      ],
      "metadata": {
        "id": "LcRvhcoIwcvf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "또는 원하는 장치에 텐서의 사본을 생성할 수 있다.\n",
        "```\n",
        "points_2 = points.to(device='cuda')\n",
        "```"
      ],
      "metadata": {
        "id": "Too1k9Ifwkx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서를 GPU에 저장하면 계산 속도가 빨라진다. 파이토치에서 텐서 API는 텐서가 위치한 CPU와 GPU에 대체로 동일하므로, 똑같은 텐서를 장치 간 이동시키고, 계산을 수행하고 다시 이동시킬 수 있어 상당히 편리하다."
      ],
      "metadata": {
        "id": "fo4at9Oxw7Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "동일한 유형의 장치가 여러 개 있다면, 즉 GPU가 두 개 이상 있다면 다음처럼 장치의 인덱스를 사용해 텐서를 저장할 장치를 정확하게 지정할 수 있다.\n",
        "```\n",
        "points_3 = points.to(device='cuda:0')\n",
        "```"
      ],
      "metadata": {
        "id": "6NS_6BDjxGNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치로 신경망 훈련하기"
      ],
      "metadata": {
        "id": "UhJwalVaxcuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import modules"
      ],
      "metadata": {
        "id": "VDpcDHSiig1C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iIqArPmUhqt-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![그림 1.14 신경망 아키텍처.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "*신경망 아키텍처*"
      ],
      "metadata": {
        "id": "W14X1eo01_K-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define model architecture"
      ],
      "metadata": {
        "id": "agp9rZ642Ld2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.cn1 = nn.Conv2d(1, 16, 3, 1)\n",
        "    self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
        "    self.dp1 = nn.Dropout2d(0.10)\n",
        "    self.dp2 = nn.Dropout2d(0.25)\n",
        "    self.fc1 = nn.Linear(4608, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cn1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.cn2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dp1(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dp2(x)\n",
        "    x = self.fc2(x)\n",
        "    op = F.log_softmax(x, dim=1)\n",
        "    return op"
      ],
      "metadata": {
        "id": "f2NZq_CKxh1T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`__init__` 함수는 모델의 중추 아키텍처, 즉 각 계층의 뉴런 개수와 함께 모든 계층을 정의한다  \n",
        "`forward` 함수는 이름에서도 알 수 있듯이 신경망에서 정보를 앞으로 전달한다. 따라서 이 함수는 각 계층에서 쓸 수 있는 모든 활성화 함수와 계층 뒤에 올 풀링이나 드롭아웃 계층을 포함한다. 이 함수는 마지막 계층의 출력, 즉 모델의 예측을 반환한다. 이 출력은 타깃 출력(정답)과 동일한 차원을 갖는다."
      ],
      "metadata": {
        "id": "yDLzFgP_6XPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 합성곱 계층의 입력은 1채널, 출력은 16채널, 커널 크기는 3, 스트라이드는 1이다.  \n",
        "1채널 입력은 모델에 공급할 흑백 이미지를 위한 것이다.  \n",
        "일반적으로 커널 크기는 홀수로 정하는데, 입력 이미지 픽셀이 중앙 픽셀을 둘러싸고 대칭으로 분포하기 때문이다.  \n",
        "이미지의 가장 중요한 시각적 특징은 특정 범위에서 발견하므로, 시각적 패턴을 찾으려면 한번에 인접한 픽셀 몇 개만을 보는 작은 커널을 쓰는 것이 낫다. 그래서 CNN으로 컴퓨터 비전 문제를 풀 때 3x3의 커널 크기를 가장 많이 쓴다.  \n",
        "이 아키텍처에는 합성곱 계층 두 개가 연속으로 있고, 각 계층은 커널 크기가 3x3이다. 공간 커버리지 관점에서는 커널 크기가 5x5인 합성곱 계층을 하나 사용하는 것과 같다. 그렇지만 작은 커널을 쓰는 계층을 여러 개 사용하면 네트워크가 더 깊어져서 더 복잡한 특징을 학습할 수 있고, 커널 크기가 작아 매개변수가 적기 때문에 즐겨쓰는 방식이다.\n",
        "합성곱 계층의 출력 채널 수는 일반적으로 입력 채널 수보다 크거나 같다. 첫 번째 합성곱 계층은 1채널 데이터를 취해 16채널을 출력한다. 즉, 이 계층은 입력 이미지로부터 16가지 정보를 탐지한다. 각 채널을 특징 맵(feature map)이라고 하고 각각에는 특징을 추출하는 전용 커널이 있다.  \n",
        "두 번째 합성곱 계층은 이미지에서 더 많은 종류의 특징을 추출하려고 채널 수를 16에서 32로 늘렸다. CNN에서는 이렇게 채널 수(또는 이미지 깊이)를 늘리는 일이 많다.  \n",
        "마지막으로 커널 크기가 겨우 3이므로 스트라이드를 1로 설정하는 것은 당연하다. 스트라이드가 커지면 합성곱 연산의 횟수가 적어지는 대신, 커널이 볼 수 있는 영역이 줄어든다."
      ],
      "metadata": {
        "id": "kPpYC0Kr68m8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define training and inference routines"
      ],
      "metadata": {
        "id": "RAQgakbh8Snx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_dataloader, optim, epoch):\n",
        "    model.train()\n",
        "    for b_i, (X, y) in enumerate(train_dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optim.zero_grad()\n",
        "        pred_prob = model(X)\n",
        "        loss = F.nll_loss(pred_prob, y) # nll: 음의 로그 우도 손실\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if b_i % 10 == 0:\n",
        "            print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.6f}'.format(\n",
        "                epoch, b_i * len(X), len(train_dataloader.dataset),\n",
        "                100. * b_i / len(train_dataloader), loss.item()))"
      ],
      "metadata": {
        "id": "4Rn54k1S6Wdo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 코드는 데이터셋에서 배치 단위로 반복하고, 주어진 장치에 데이터셋 사본을 만들고, 신경망 모델에서 추출된 데이터를 앞으로 전달하고, 모델의 예측값과 정답 사이의 손실을 계산하고, 주어진 옵티마이저를 사용해 모델 가중치를 조정하고, 배치 10개마다 훈련 로그를 출력한다. 이 전체 과정을 한 번 수행하는 것을 1세대(epoch)라고 한다. 즉 1 epoch은 데이터셋 전체를 한 번 읽는 기간을 뜻한다."
      ],
      "metadata": {
        "id": "re5bz5gP8muX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_dataloader):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    success = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred_prob = model(X)\n",
        "            loss += F.nll_loss(pred_prob, y, reduction='sum').item()  # 배치별 손실 합\n",
        "            pred = pred_prob.argmax(dim=1, keepdim=True)  # 가장 가능성이 높은 예측을 얻기 위해 armax 사용\n",
        "            success += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    loss /= len(test_dataloader.dataset)\n",
        "\n",
        "    print('\\nTest dataset: Overall Loss: {:.4f}, Overall Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        loss, success, len(test_dataloader.dataset),\n",
        "        100. * success / len(test_dataloader.dataset)))"
      ],
      "metadata": {
        "id": "cAoddOJE8kFo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 함수와 유일한 차이는 모델 예측값과 정답을 가지고 계산한 손실이 옵티마이저를 사용해 모델 가중치를 조정하는 데 사용되지 않는다는 것이다. 그 대신, 손실을 사용해 전체 테스트 배치에서 테스트 오차 총합을 계산한다."
      ],
      "metadata": {
        "id": "QIhbUTKH9Dve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create data loaders"
      ],
      "metadata": {
        "id": "TE4tRDYk9OUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균 값과 표준 편차 값은 훈련 데이터셋의 이미지 전체의 픽셀값 전체에 대한 평균으로 계산된다.\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1302,), (0.3069,))])), # train_X.mean()/256. and train_X.std()/256.\n",
        "    batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1302,), (0.3069,))\n",
        "                   ])),\n",
        "    batch_size=500, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKX5PaBp84Fc",
        "outputId": "fdcd3794-8cd9-439c-f46d-5ce4f41fb3ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 80264315.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 7215182.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25227037.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14216812.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "model = ConvNet()\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=0.5)"
      ],
      "metadata": {
        "id": "7Y2IfvWX9W_H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model training"
      ],
      "metadata": {
        "id": "wiF_xgreJ9Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 3):\n",
        "    train(model, device, train_dataloader, optimizer, epoch)\n",
        "    test(model, device, test_dataloader)"
      ],
      "metadata": {
        "id": "jsvKJ9rU937P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f3a875-1b54-4363-ced8-4a559115a6aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 [0/60000 (0%)]\t training loss: 0.376997\n",
            "epoch: 1 [320/60000 (1%)]\t training loss: 0.319187\n",
            "epoch: 1 [640/60000 (1%)]\t training loss: 0.248670\n",
            "epoch: 1 [960/60000 (2%)]\t training loss: 0.300421\n",
            "epoch: 1 [1280/60000 (2%)]\t training loss: 0.189865\n",
            "epoch: 1 [1600/60000 (3%)]\t training loss: 0.474944\n",
            "epoch: 1 [1920/60000 (3%)]\t training loss: 0.426032\n",
            "epoch: 1 [2240/60000 (4%)]\t training loss: 0.414782\n",
            "epoch: 1 [2560/60000 (4%)]\t training loss: 0.040511\n",
            "epoch: 1 [2880/60000 (5%)]\t training loss: 0.167950\n",
            "epoch: 1 [3200/60000 (5%)]\t training loss: 0.099848\n",
            "epoch: 1 [3520/60000 (6%)]\t training loss: 0.347144\n",
            "epoch: 1 [3840/60000 (6%)]\t training loss: 0.093891\n",
            "epoch: 1 [4160/60000 (7%)]\t training loss: 0.201355\n",
            "epoch: 1 [4480/60000 (7%)]\t training loss: 0.477813\n",
            "epoch: 1 [4800/60000 (8%)]\t training loss: 0.095191\n",
            "epoch: 1 [5120/60000 (9%)]\t training loss: 0.032258\n",
            "epoch: 1 [5440/60000 (9%)]\t training loss: 0.528764\n",
            "epoch: 1 [5760/60000 (10%)]\t training loss: 0.202198\n",
            "epoch: 1 [6080/60000 (10%)]\t training loss: 0.150005\n",
            "epoch: 1 [6400/60000 (11%)]\t training loss: 0.231912\n",
            "epoch: 1 [6720/60000 (11%)]\t training loss: 0.133004\n",
            "epoch: 1 [7040/60000 (12%)]\t training loss: 0.310125\n",
            "epoch: 1 [7360/60000 (12%)]\t training loss: 0.288433\n",
            "epoch: 1 [7680/60000 (13%)]\t training loss: 0.076313\n",
            "epoch: 1 [8000/60000 (13%)]\t training loss: 0.139658\n",
            "epoch: 1 [8320/60000 (14%)]\t training loss: 0.116486\n",
            "epoch: 1 [8640/60000 (14%)]\t training loss: 0.250983\n",
            "epoch: 1 [8960/60000 (15%)]\t training loss: 0.059046\n",
            "epoch: 1 [9280/60000 (15%)]\t training loss: 0.629879\n",
            "epoch: 1 [9600/60000 (16%)]\t training loss: 0.174643\n",
            "epoch: 1 [9920/60000 (17%)]\t training loss: 0.342882\n",
            "epoch: 1 [10240/60000 (17%)]\t training loss: 0.046720\n",
            "epoch: 1 [10560/60000 (18%)]\t training loss: 0.245356\n",
            "epoch: 1 [10880/60000 (18%)]\t training loss: 0.038179\n",
            "epoch: 1 [11200/60000 (19%)]\t training loss: 0.022248\n",
            "epoch: 1 [11520/60000 (19%)]\t training loss: 0.182185\n",
            "epoch: 1 [11840/60000 (20%)]\t training loss: 0.267787\n",
            "epoch: 1 [12160/60000 (20%)]\t training loss: 0.336384\n",
            "epoch: 1 [12480/60000 (21%)]\t training loss: 0.124918\n",
            "epoch: 1 [12800/60000 (21%)]\t training loss: 0.050278\n",
            "epoch: 1 [13120/60000 (22%)]\t training loss: 0.152994\n",
            "epoch: 1 [13440/60000 (22%)]\t training loss: 0.189602\n",
            "epoch: 1 [13760/60000 (23%)]\t training loss: 0.257656\n",
            "epoch: 1 [14080/60000 (23%)]\t training loss: 0.413875\n",
            "epoch: 1 [14400/60000 (24%)]\t training loss: 0.208237\n",
            "epoch: 1 [14720/60000 (25%)]\t training loss: 0.119292\n",
            "epoch: 1 [15040/60000 (25%)]\t training loss: 0.122731\n",
            "epoch: 1 [15360/60000 (26%)]\t training loss: 0.202920\n",
            "epoch: 1 [15680/60000 (26%)]\t training loss: 0.085473\n",
            "epoch: 1 [16000/60000 (27%)]\t training loss: 0.389325\n",
            "epoch: 1 [16320/60000 (27%)]\t training loss: 0.215363\n",
            "epoch: 1 [16640/60000 (28%)]\t training loss: 0.523909\n",
            "epoch: 1 [16960/60000 (28%)]\t training loss: 0.134409\n",
            "epoch: 1 [17280/60000 (29%)]\t training loss: 0.112032\n",
            "epoch: 1 [17600/60000 (29%)]\t training loss: 0.089221\n",
            "epoch: 1 [17920/60000 (30%)]\t training loss: 0.099639\n",
            "epoch: 1 [18240/60000 (30%)]\t training loss: 0.063403\n",
            "epoch: 1 [18560/60000 (31%)]\t training loss: 0.124763\n",
            "epoch: 1 [18880/60000 (31%)]\t training loss: 0.073814\n",
            "epoch: 1 [19200/60000 (32%)]\t training loss: 0.035853\n",
            "epoch: 1 [19520/60000 (33%)]\t training loss: 0.168062\n",
            "epoch: 1 [19840/60000 (33%)]\t training loss: 0.222498\n",
            "epoch: 1 [20160/60000 (34%)]\t training loss: 0.347449\n",
            "epoch: 1 [20480/60000 (34%)]\t training loss: 0.179279\n",
            "epoch: 1 [20800/60000 (35%)]\t training loss: 0.149582\n",
            "epoch: 1 [21120/60000 (35%)]\t training loss: 0.209436\n",
            "epoch: 1 [21440/60000 (36%)]\t training loss: 0.354510\n",
            "epoch: 1 [21760/60000 (36%)]\t training loss: 0.066153\n",
            "epoch: 1 [22080/60000 (37%)]\t training loss: 0.247459\n",
            "epoch: 1 [22400/60000 (37%)]\t training loss: 0.011063\n",
            "epoch: 1 [22720/60000 (38%)]\t training loss: 0.043206\n",
            "epoch: 1 [23040/60000 (38%)]\t training loss: 0.303809\n",
            "epoch: 1 [23360/60000 (39%)]\t training loss: 0.040000\n",
            "epoch: 1 [23680/60000 (39%)]\t training loss: 0.140003\n",
            "epoch: 1 [24000/60000 (40%)]\t training loss: 0.078406\n",
            "epoch: 1 [24320/60000 (41%)]\t training loss: 0.220983\n",
            "epoch: 1 [24640/60000 (41%)]\t training loss: 0.142119\n",
            "epoch: 1 [24960/60000 (42%)]\t training loss: 0.050427\n",
            "epoch: 1 [25280/60000 (42%)]\t training loss: 0.074231\n",
            "epoch: 1 [25600/60000 (43%)]\t training loss: 0.018678\n",
            "epoch: 1 [25920/60000 (43%)]\t training loss: 0.051222\n",
            "epoch: 1 [26240/60000 (44%)]\t training loss: 0.101088\n",
            "epoch: 1 [26560/60000 (44%)]\t training loss: 0.008002\n",
            "epoch: 1 [26880/60000 (45%)]\t training loss: 0.024775\n",
            "epoch: 1 [27200/60000 (45%)]\t training loss: 0.048918\n",
            "epoch: 1 [27520/60000 (46%)]\t training loss: 0.021545\n",
            "epoch: 1 [27840/60000 (46%)]\t training loss: 0.150359\n",
            "epoch: 1 [28160/60000 (47%)]\t training loss: 0.047271\n",
            "epoch: 1 [28480/60000 (47%)]\t training loss: 0.015102\n",
            "epoch: 1 [28800/60000 (48%)]\t training loss: 0.049610\n",
            "epoch: 1 [29120/60000 (49%)]\t training loss: 0.010988\n",
            "epoch: 1 [29440/60000 (49%)]\t training loss: 0.298221\n",
            "epoch: 1 [29760/60000 (50%)]\t training loss: 0.077214\n",
            "epoch: 1 [30080/60000 (50%)]\t training loss: 0.034290\n",
            "epoch: 1 [30400/60000 (51%)]\t training loss: 0.296798\n",
            "epoch: 1 [30720/60000 (51%)]\t training loss: 0.097268\n",
            "epoch: 1 [31040/60000 (52%)]\t training loss: 0.138682\n",
            "epoch: 1 [31360/60000 (52%)]\t training loss: 0.007094\n",
            "epoch: 1 [31680/60000 (53%)]\t training loss: 0.006504\n",
            "epoch: 1 [32000/60000 (53%)]\t training loss: 0.049683\n",
            "epoch: 1 [32320/60000 (54%)]\t training loss: 0.101632\n",
            "epoch: 1 [32640/60000 (54%)]\t training loss: 0.038940\n",
            "epoch: 1 [32960/60000 (55%)]\t training loss: 0.338056\n",
            "epoch: 1 [33280/60000 (55%)]\t training loss: 0.020713\n",
            "epoch: 1 [33600/60000 (56%)]\t training loss: 0.266027\n",
            "epoch: 1 [33920/60000 (57%)]\t training loss: 0.053394\n",
            "epoch: 1 [34240/60000 (57%)]\t training loss: 0.234284\n",
            "epoch: 1 [34560/60000 (58%)]\t training loss: 0.031968\n",
            "epoch: 1 [34880/60000 (58%)]\t training loss: 0.009791\n",
            "epoch: 1 [35200/60000 (59%)]\t training loss: 0.159877\n",
            "epoch: 1 [35520/60000 (59%)]\t training loss: 0.018825\n",
            "epoch: 1 [35840/60000 (60%)]\t training loss: 0.026752\n",
            "epoch: 1 [36160/60000 (60%)]\t training loss: 0.050563\n",
            "epoch: 1 [36480/60000 (61%)]\t training loss: 0.116843\n",
            "epoch: 1 [36800/60000 (61%)]\t training loss: 0.337669\n",
            "epoch: 1 [37120/60000 (62%)]\t training loss: 0.054978\n",
            "epoch: 1 [37440/60000 (62%)]\t training loss: 0.036064\n",
            "epoch: 1 [37760/60000 (63%)]\t training loss: 0.030182\n",
            "epoch: 1 [38080/60000 (63%)]\t training loss: 0.086986\n",
            "epoch: 1 [38400/60000 (64%)]\t training loss: 0.034519\n",
            "epoch: 1 [38720/60000 (65%)]\t training loss: 0.053136\n",
            "epoch: 1 [39040/60000 (65%)]\t training loss: 0.124687\n",
            "epoch: 1 [39360/60000 (66%)]\t training loss: 0.178313\n",
            "epoch: 1 [39680/60000 (66%)]\t training loss: 0.046508\n",
            "epoch: 1 [40000/60000 (67%)]\t training loss: 0.311808\n",
            "epoch: 1 [40320/60000 (67%)]\t training loss: 0.131487\n",
            "epoch: 1 [40640/60000 (68%)]\t training loss: 0.063950\n",
            "epoch: 1 [40960/60000 (68%)]\t training loss: 0.391423\n",
            "epoch: 1 [41280/60000 (69%)]\t training loss: 0.021208\n",
            "epoch: 1 [41600/60000 (69%)]\t training loss: 0.200547\n",
            "epoch: 1 [41920/60000 (70%)]\t training loss: 0.053392\n",
            "epoch: 1 [42240/60000 (70%)]\t training loss: 0.360160\n",
            "epoch: 1 [42560/60000 (71%)]\t training loss: 0.101158\n",
            "epoch: 1 [42880/60000 (71%)]\t training loss: 0.026083\n",
            "epoch: 1 [43200/60000 (72%)]\t training loss: 0.140405\n",
            "epoch: 1 [43520/60000 (73%)]\t training loss: 0.139055\n",
            "epoch: 1 [43840/60000 (73%)]\t training loss: 0.012734\n",
            "epoch: 1 [44160/60000 (74%)]\t training loss: 0.029321\n",
            "epoch: 1 [44480/60000 (74%)]\t training loss: 0.007910\n",
            "epoch: 1 [44800/60000 (75%)]\t training loss: 0.121681\n",
            "epoch: 1 [45120/60000 (75%)]\t training loss: 0.056245\n",
            "epoch: 1 [45440/60000 (76%)]\t training loss: 0.066546\n",
            "epoch: 1 [45760/60000 (76%)]\t training loss: 0.119724\n",
            "epoch: 1 [46080/60000 (77%)]\t training loss: 0.156416\n",
            "epoch: 1 [46400/60000 (77%)]\t training loss: 0.063161\n",
            "epoch: 1 [46720/60000 (78%)]\t training loss: 0.010734\n",
            "epoch: 1 [47040/60000 (78%)]\t training loss: 0.012154\n",
            "epoch: 1 [47360/60000 (79%)]\t training loss: 0.071329\n",
            "epoch: 1 [47680/60000 (79%)]\t training loss: 0.067053\n",
            "epoch: 1 [48000/60000 (80%)]\t training loss: 0.087117\n",
            "epoch: 1 [48320/60000 (81%)]\t training loss: 0.020330\n",
            "epoch: 1 [48640/60000 (81%)]\t training loss: 0.082997\n",
            "epoch: 1 [48960/60000 (82%)]\t training loss: 0.146962\n",
            "epoch: 1 [49280/60000 (82%)]\t training loss: 0.037472\n",
            "epoch: 1 [49600/60000 (83%)]\t training loss: 0.042351\n",
            "epoch: 1 [49920/60000 (83%)]\t training loss: 0.039883\n",
            "epoch: 1 [50240/60000 (84%)]\t training loss: 0.065938\n",
            "epoch: 1 [50560/60000 (84%)]\t training loss: 0.008203\n",
            "epoch: 1 [50880/60000 (85%)]\t training loss: 0.039115\n",
            "epoch: 1 [51200/60000 (85%)]\t training loss: 0.045378\n",
            "epoch: 1 [51520/60000 (86%)]\t training loss: 0.023862\n",
            "epoch: 1 [51840/60000 (86%)]\t training loss: 0.133458\n",
            "epoch: 1 [52160/60000 (87%)]\t training loss: 0.013910\n",
            "epoch: 1 [52480/60000 (87%)]\t training loss: 0.295700\n",
            "epoch: 1 [52800/60000 (88%)]\t training loss: 0.096486\n",
            "epoch: 1 [53120/60000 (89%)]\t training loss: 0.012978\n",
            "epoch: 1 [53440/60000 (89%)]\t training loss: 0.041773\n",
            "epoch: 1 [53760/60000 (90%)]\t training loss: 0.233003\n",
            "epoch: 1 [54080/60000 (90%)]\t training loss: 0.028156\n",
            "epoch: 1 [54400/60000 (91%)]\t training loss: 0.038109\n",
            "epoch: 1 [54720/60000 (91%)]\t training loss: 0.043092\n",
            "epoch: 1 [55040/60000 (92%)]\t training loss: 0.102327\n",
            "epoch: 1 [55360/60000 (92%)]\t training loss: 0.020899\n",
            "epoch: 1 [55680/60000 (93%)]\t training loss: 0.002766\n",
            "epoch: 1 [56000/60000 (93%)]\t training loss: 0.026523\n",
            "epoch: 1 [56320/60000 (94%)]\t training loss: 0.025251\n",
            "epoch: 1 [56640/60000 (94%)]\t training loss: 0.335299\n",
            "epoch: 1 [56960/60000 (95%)]\t training loss: 0.014832\n",
            "epoch: 1 [57280/60000 (95%)]\t training loss: 0.031486\n",
            "epoch: 1 [57600/60000 (96%)]\t training loss: 0.129099\n",
            "epoch: 1 [57920/60000 (97%)]\t training loss: 0.124662\n",
            "epoch: 1 [58240/60000 (97%)]\t training loss: 0.023937\n",
            "epoch: 1 [58560/60000 (98%)]\t training loss: 0.023656\n",
            "epoch: 1 [58880/60000 (98%)]\t training loss: 0.012951\n",
            "epoch: 1 [59200/60000 (99%)]\t training loss: 0.041299\n",
            "epoch: 1 [59520/60000 (99%)]\t training loss: 0.060613\n",
            "epoch: 1 [59840/60000 (100%)]\t training loss: 0.004899\n",
            "\n",
            "Test dataset: Overall Loss: 0.0502, Overall Accuracy: 9836/10000 (98%)\n",
            "\n",
            "epoch: 2 [0/60000 (0%)]\t training loss: 0.204293\n",
            "epoch: 2 [320/60000 (1%)]\t training loss: 0.021895\n",
            "epoch: 2 [640/60000 (1%)]\t training loss: 0.044279\n",
            "epoch: 2 [960/60000 (2%)]\t training loss: 0.003832\n",
            "epoch: 2 [1280/60000 (2%)]\t training loss: 0.069655\n",
            "epoch: 2 [1600/60000 (3%)]\t training loss: 0.010192\n",
            "epoch: 2 [1920/60000 (3%)]\t training loss: 0.085127\n",
            "epoch: 2 [2240/60000 (4%)]\t training loss: 0.009313\n",
            "epoch: 2 [2560/60000 (4%)]\t training loss: 0.247138\n",
            "epoch: 2 [2880/60000 (5%)]\t training loss: 0.002024\n",
            "epoch: 2 [3200/60000 (5%)]\t training loss: 0.014684\n",
            "epoch: 2 [3520/60000 (6%)]\t training loss: 0.300184\n",
            "epoch: 2 [3840/60000 (6%)]\t training loss: 0.097282\n",
            "epoch: 2 [4160/60000 (7%)]\t training loss: 0.071839\n",
            "epoch: 2 [4480/60000 (7%)]\t training loss: 0.006338\n",
            "epoch: 2 [4800/60000 (8%)]\t training loss: 0.163764\n",
            "epoch: 2 [5120/60000 (9%)]\t training loss: 0.160371\n",
            "epoch: 2 [5440/60000 (9%)]\t training loss: 0.009058\n",
            "epoch: 2 [5760/60000 (10%)]\t training loss: 0.052079\n",
            "epoch: 2 [6080/60000 (10%)]\t training loss: 0.102825\n",
            "epoch: 2 [6400/60000 (11%)]\t training loss: 0.015324\n",
            "epoch: 2 [6720/60000 (11%)]\t training loss: 0.264892\n",
            "epoch: 2 [7040/60000 (12%)]\t training loss: 0.387494\n",
            "epoch: 2 [7360/60000 (12%)]\t training loss: 0.016811\n",
            "epoch: 2 [7680/60000 (13%)]\t training loss: 0.092462\n",
            "epoch: 2 [8000/60000 (13%)]\t training loss: 0.080296\n",
            "epoch: 2 [8320/60000 (14%)]\t training loss: 0.009914\n",
            "epoch: 2 [8640/60000 (14%)]\t training loss: 0.114754\n",
            "epoch: 2 [8960/60000 (15%)]\t training loss: 0.088151\n",
            "epoch: 2 [9280/60000 (15%)]\t training loss: 0.057291\n",
            "epoch: 2 [9600/60000 (16%)]\t training loss: 0.006658\n",
            "epoch: 2 [9920/60000 (17%)]\t training loss: 0.043832\n",
            "epoch: 2 [10240/60000 (17%)]\t training loss: 0.028794\n",
            "epoch: 2 [10560/60000 (18%)]\t training loss: 0.025205\n",
            "epoch: 2 [10880/60000 (18%)]\t training loss: 0.004573\n",
            "epoch: 2 [11200/60000 (19%)]\t training loss: 0.063632\n",
            "epoch: 2 [11520/60000 (19%)]\t training loss: 0.005143\n",
            "epoch: 2 [11840/60000 (20%)]\t training loss: 0.037653\n",
            "epoch: 2 [12160/60000 (20%)]\t training loss: 0.171526\n",
            "epoch: 2 [12480/60000 (21%)]\t training loss: 0.010786\n",
            "epoch: 2 [12800/60000 (21%)]\t training loss: 0.054997\n",
            "epoch: 2 [13120/60000 (22%)]\t training loss: 0.087079\n",
            "epoch: 2 [13440/60000 (22%)]\t training loss: 0.122971\n",
            "epoch: 2 [13760/60000 (23%)]\t training loss: 0.111767\n",
            "epoch: 2 [14080/60000 (23%)]\t training loss: 0.008780\n",
            "epoch: 2 [14400/60000 (24%)]\t training loss: 0.014254\n",
            "epoch: 2 [14720/60000 (25%)]\t training loss: 0.063354\n",
            "epoch: 2 [15040/60000 (25%)]\t training loss: 0.004744\n",
            "epoch: 2 [15360/60000 (26%)]\t training loss: 0.032206\n",
            "epoch: 2 [15680/60000 (26%)]\t training loss: 0.003099\n",
            "epoch: 2 [16000/60000 (27%)]\t training loss: 0.029304\n",
            "epoch: 2 [16320/60000 (27%)]\t training loss: 0.021860\n",
            "epoch: 2 [16640/60000 (28%)]\t training loss: 0.040235\n",
            "epoch: 2 [16960/60000 (28%)]\t training loss: 0.083437\n",
            "epoch: 2 [17280/60000 (29%)]\t training loss: 0.014417\n",
            "epoch: 2 [17600/60000 (29%)]\t training loss: 0.029238\n",
            "epoch: 2 [17920/60000 (30%)]\t training loss: 0.067543\n",
            "epoch: 2 [18240/60000 (30%)]\t training loss: 0.034181\n",
            "epoch: 2 [18560/60000 (31%)]\t training loss: 0.004323\n",
            "epoch: 2 [18880/60000 (31%)]\t training loss: 0.290713\n",
            "epoch: 2 [19200/60000 (32%)]\t training loss: 0.019643\n",
            "epoch: 2 [19520/60000 (33%)]\t training loss: 0.065280\n",
            "epoch: 2 [19840/60000 (33%)]\t training loss: 0.089888\n",
            "epoch: 2 [20160/60000 (34%)]\t training loss: 0.021472\n",
            "epoch: 2 [20480/60000 (34%)]\t training loss: 0.083420\n",
            "epoch: 2 [20800/60000 (35%)]\t training loss: 0.010161\n",
            "epoch: 2 [21120/60000 (35%)]\t training loss: 0.025760\n",
            "epoch: 2 [21440/60000 (36%)]\t training loss: 0.104229\n",
            "epoch: 2 [21760/60000 (36%)]\t training loss: 0.011722\n",
            "epoch: 2 [22080/60000 (37%)]\t training loss: 0.028467\n",
            "epoch: 2 [22400/60000 (37%)]\t training loss: 0.018233\n",
            "epoch: 2 [22720/60000 (38%)]\t training loss: 0.071944\n",
            "epoch: 2 [23040/60000 (38%)]\t training loss: 0.038158\n",
            "epoch: 2 [23360/60000 (39%)]\t training loss: 0.009010\n",
            "epoch: 2 [23680/60000 (39%)]\t training loss: 0.088960\n",
            "epoch: 2 [24000/60000 (40%)]\t training loss: 0.032335\n",
            "epoch: 2 [24320/60000 (41%)]\t training loss: 0.002764\n",
            "epoch: 2 [24640/60000 (41%)]\t training loss: 0.094178\n",
            "epoch: 2 [24960/60000 (42%)]\t training loss: 0.013583\n",
            "epoch: 2 [25280/60000 (42%)]\t training loss: 0.091575\n",
            "epoch: 2 [25600/60000 (43%)]\t training loss: 0.002247\n",
            "epoch: 2 [25920/60000 (43%)]\t training loss: 0.022214\n",
            "epoch: 2 [26240/60000 (44%)]\t training loss: 0.169535\n",
            "epoch: 2 [26560/60000 (44%)]\t training loss: 0.107564\n",
            "epoch: 2 [26880/60000 (45%)]\t training loss: 0.073962\n",
            "epoch: 2 [27200/60000 (45%)]\t training loss: 0.003164\n",
            "epoch: 2 [27520/60000 (46%)]\t training loss: 0.003293\n",
            "epoch: 2 [27840/60000 (46%)]\t training loss: 0.022898\n",
            "epoch: 2 [28160/60000 (47%)]\t training loss: 0.007053\n",
            "epoch: 2 [28480/60000 (47%)]\t training loss: 0.030328\n",
            "epoch: 2 [28800/60000 (48%)]\t training loss: 0.010028\n",
            "epoch: 2 [29120/60000 (49%)]\t training loss: 0.070910\n",
            "epoch: 2 [29440/60000 (49%)]\t training loss: 0.005229\n",
            "epoch: 2 [29760/60000 (50%)]\t training loss: 0.018905\n",
            "epoch: 2 [30080/60000 (50%)]\t training loss: 0.086488\n",
            "epoch: 2 [30400/60000 (51%)]\t training loss: 0.113208\n",
            "epoch: 2 [30720/60000 (51%)]\t training loss: 0.004965\n",
            "epoch: 2 [31040/60000 (52%)]\t training loss: 0.161171\n",
            "epoch: 2 [31360/60000 (52%)]\t training loss: 0.178229\n",
            "epoch: 2 [31680/60000 (53%)]\t training loss: 0.125332\n",
            "epoch: 2 [32000/60000 (53%)]\t training loss: 0.015276\n",
            "epoch: 2 [32320/60000 (54%)]\t training loss: 0.035101\n",
            "epoch: 2 [32640/60000 (54%)]\t training loss: 0.252633\n",
            "epoch: 2 [32960/60000 (55%)]\t training loss: 0.057742\n",
            "epoch: 2 [33280/60000 (55%)]\t training loss: 0.291759\n",
            "epoch: 2 [33600/60000 (56%)]\t training loss: 0.152678\n",
            "epoch: 2 [33920/60000 (57%)]\t training loss: 0.081214\n",
            "epoch: 2 [34240/60000 (57%)]\t training loss: 0.015034\n",
            "epoch: 2 [34560/60000 (58%)]\t training loss: 0.036298\n",
            "epoch: 2 [34880/60000 (58%)]\t training loss: 0.010339\n",
            "epoch: 2 [35200/60000 (59%)]\t training loss: 0.051682\n",
            "epoch: 2 [35520/60000 (59%)]\t training loss: 0.018944\n",
            "epoch: 2 [35840/60000 (60%)]\t training loss: 0.177090\n",
            "epoch: 2 [36160/60000 (60%)]\t training loss: 0.022131\n",
            "epoch: 2 [36480/60000 (61%)]\t training loss: 0.153016\n",
            "epoch: 2 [36800/60000 (61%)]\t training loss: 0.004628\n",
            "epoch: 2 [37120/60000 (62%)]\t training loss: 0.004573\n",
            "epoch: 2 [37440/60000 (62%)]\t training loss: 0.000483\n",
            "epoch: 2 [37760/60000 (63%)]\t training loss: 0.001398\n",
            "epoch: 2 [38080/60000 (63%)]\t training loss: 0.094453\n",
            "epoch: 2 [38400/60000 (64%)]\t training loss: 0.018362\n",
            "epoch: 2 [38720/60000 (65%)]\t training loss: 0.005080\n",
            "epoch: 2 [39040/60000 (65%)]\t training loss: 0.158671\n",
            "epoch: 2 [39360/60000 (66%)]\t training loss: 0.110689\n",
            "epoch: 2 [39680/60000 (66%)]\t training loss: 0.007729\n",
            "epoch: 2 [40000/60000 (67%)]\t training loss: 0.075083\n",
            "epoch: 2 [40320/60000 (67%)]\t training loss: 0.014020\n",
            "epoch: 2 [40640/60000 (68%)]\t training loss: 0.046343\n",
            "epoch: 2 [40960/60000 (68%)]\t training loss: 0.020943\n",
            "epoch: 2 [41280/60000 (69%)]\t training loss: 0.008463\n",
            "epoch: 2 [41600/60000 (69%)]\t training loss: 0.015746\n",
            "epoch: 2 [41920/60000 (70%)]\t training loss: 0.175829\n",
            "epoch: 2 [42240/60000 (70%)]\t training loss: 0.114615\n",
            "epoch: 2 [42560/60000 (71%)]\t training loss: 0.032294\n",
            "epoch: 2 [42880/60000 (71%)]\t training loss: 0.002185\n",
            "epoch: 2 [43200/60000 (72%)]\t training loss: 0.094751\n",
            "epoch: 2 [43520/60000 (73%)]\t training loss: 0.021711\n",
            "epoch: 2 [43840/60000 (73%)]\t training loss: 0.008272\n",
            "epoch: 2 [44160/60000 (74%)]\t training loss: 0.076728\n",
            "epoch: 2 [44480/60000 (74%)]\t training loss: 0.056056\n",
            "epoch: 2 [44800/60000 (75%)]\t training loss: 0.003849\n",
            "epoch: 2 [45120/60000 (75%)]\t training loss: 0.221358\n",
            "epoch: 2 [45440/60000 (76%)]\t training loss: 0.005532\n",
            "epoch: 2 [45760/60000 (76%)]\t training loss: 0.018303\n",
            "epoch: 2 [46080/60000 (77%)]\t training loss: 0.010631\n",
            "epoch: 2 [46400/60000 (77%)]\t training loss: 0.010149\n",
            "epoch: 2 [46720/60000 (78%)]\t training loss: 0.003921\n",
            "epoch: 2 [47040/60000 (78%)]\t training loss: 0.001051\n",
            "epoch: 2 [47360/60000 (79%)]\t training loss: 0.007600\n",
            "epoch: 2 [47680/60000 (79%)]\t training loss: 0.065053\n",
            "epoch: 2 [48000/60000 (80%)]\t training loss: 0.037160\n",
            "epoch: 2 [48320/60000 (81%)]\t training loss: 0.019286\n",
            "epoch: 2 [48640/60000 (81%)]\t training loss: 0.011853\n",
            "epoch: 2 [48960/60000 (82%)]\t training loss: 0.049803\n",
            "epoch: 2 [49280/60000 (82%)]\t training loss: 0.059741\n",
            "epoch: 2 [49600/60000 (83%)]\t training loss: 0.258115\n",
            "epoch: 2 [49920/60000 (83%)]\t training loss: 0.088820\n",
            "epoch: 2 [50240/60000 (84%)]\t training loss: 0.004097\n",
            "epoch: 2 [50560/60000 (84%)]\t training loss: 0.083645\n",
            "epoch: 2 [50880/60000 (85%)]\t training loss: 0.008853\n",
            "epoch: 2 [51200/60000 (85%)]\t training loss: 0.010603\n",
            "epoch: 2 [51520/60000 (86%)]\t training loss: 0.011514\n",
            "epoch: 2 [51840/60000 (86%)]\t training loss: 0.007524\n",
            "epoch: 2 [52160/60000 (87%)]\t training loss: 0.178741\n",
            "epoch: 2 [52480/60000 (87%)]\t training loss: 0.506752\n",
            "epoch: 2 [52800/60000 (88%)]\t training loss: 0.061216\n",
            "epoch: 2 [53120/60000 (89%)]\t training loss: 0.061164\n",
            "epoch: 2 [53440/60000 (89%)]\t training loss: 0.004350\n",
            "epoch: 2 [53760/60000 (90%)]\t training loss: 0.001886\n",
            "epoch: 2 [54080/60000 (90%)]\t training loss: 0.006838\n",
            "epoch: 2 [54400/60000 (91%)]\t training loss: 0.003383\n",
            "epoch: 2 [54720/60000 (91%)]\t training loss: 0.007702\n",
            "epoch: 2 [55040/60000 (92%)]\t training loss: 0.021065\n",
            "epoch: 2 [55360/60000 (92%)]\t training loss: 0.004521\n",
            "epoch: 2 [55680/60000 (93%)]\t training loss: 0.001886\n",
            "epoch: 2 [56000/60000 (93%)]\t training loss: 0.096775\n",
            "epoch: 2 [56320/60000 (94%)]\t training loss: 0.019755\n",
            "epoch: 2 [56640/60000 (94%)]\t training loss: 0.082611\n",
            "epoch: 2 [56960/60000 (95%)]\t training loss: 0.005972\n",
            "epoch: 2 [57280/60000 (95%)]\t training loss: 0.092987\n",
            "epoch: 2 [57600/60000 (96%)]\t training loss: 0.009963\n",
            "epoch: 2 [57920/60000 (97%)]\t training loss: 0.005160\n",
            "epoch: 2 [58240/60000 (97%)]\t training loss: 0.101206\n",
            "epoch: 2 [58560/60000 (98%)]\t training loss: 0.008056\n",
            "epoch: 2 [58880/60000 (98%)]\t training loss: 0.096243\n",
            "epoch: 2 [59200/60000 (99%)]\t training loss: 0.010185\n",
            "epoch: 2 [59520/60000 (99%)]\t training loss: 0.003499\n",
            "epoch: 2 [59840/60000 (100%)]\t training loss: 0.021019\n",
            "\n",
            "Test dataset: Overall Loss: 0.0433, Overall Accuracy: 9853/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run inference on trained model"
      ],
      "metadata": {
        "id": "ioe8Q2H2MSHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = enumerate(test_dataloader)\n",
        "b_i, (sample_data, sample_targets) = next(test_samples)\n",
        "\n",
        "plt.imshow(sample_data[0][0], cmap='gray', interpolation='none')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "EQJ6SYKyJ_HN",
        "outputId": "0f8e3101-0a25-442b-a1a2-d288edb5c7d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaqElEQVR4nO3df2xV9f3H8VeL9ILaXiylvb2jQEEFwy8ng9rwYygNtC4GtEtA/QMWAoFdzLDzx7qIKFvSjSWOuCD+s8BMxF+JQCRLMym2hNliqDDCph3tugGBFsVxbylSGP18/yDer1cKeMq9ffdeno/kJPTe8+l9ezzhyWlvT9Occ04AAPSxdOsBAAA3JwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM3GI9wLd1d3frxIkTyszMVFpamvU4AACPnHPq6OhQMBhUevrVr3P6XYBOnDihgoIC6zEAADfo2LFjGj58+FWf73dfgsvMzLQeAQAQB9f7+zxhAdq4caNGjRqlQYMGqaioSB9//PF3WseX3QAgNVzv7/OEBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUqUS8HAAgGbkEmDZtmguFQtGPL1265ILBoKuqqrru2nA47CSxsbGxsSX5Fg6Hr/n3fdyvgC5cuKDGxkaVlJREH0tPT1dJSYnq6+uv2L+rq0uRSCRmAwCkvrgH6IsvvtClS5eUl5cX83heXp7a2tqu2L+qqkp+vz+68Q44ALg5mL8LrrKyUuFwOLodO3bMeiQAQB+I+88B5eTkaMCAAWpvb495vL29XYFA4Ir9fT6ffD5fvMcAAPRzcb8CysjI0JQpU1RTUxN9rLu7WzU1NSouLo73ywEAklRC7oRQUVGhxYsX6wc/+IGmTZumDRs2qLOzUz/5yU8S8XIAgCSUkAAtXLhQn3/+uV544QW1tbXp3nvvVXV19RVvTAAA3LzSnHPOeohvikQi8vv91mMAAG5QOBxWVlbWVZ83fxccAODmRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMQ9QC+++KLS0tJitnHjxsX7ZQAASe6WRHzS8ePHa9euXf//Irck5GUAAEksIWW45ZZbFAgEEvGpAQApIiHfAzpy5IiCwaBGjx6tJ554QkePHr3qvl1dXYpEIjEbACD1xT1ARUVF2rJli6qrq7Vp0ya1trZq5syZ6ujo6HH/qqoq+f3+6FZQUBDvkQAA/VCac84l8gXOnDmjkSNH6uWXX9bSpUuveL6rq0tdXV3RjyORCBECgBQQDoeVlZV11ecT/u6AIUOG6O6771Zzc3OPz/t8Pvl8vkSPAQDoZxL+c0Bnz55VS0uL8vPzE/1SAIAkEvcAPf3006qrq9O///1vffTRR3rkkUc0YMAAPfbYY/F+KQBAEov7l+COHz+uxx57TKdPn9awYcM0Y8YMNTQ0aNiwYfF+KQBAEkv4mxC8ikQi8vv91mMAAG7Q9d6EwL3gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATCf+FdOhbP/7xjz2vWbZsWa9e68SJE57XnD9/3vOaN954w/OatrY2z2skXfUXJwKIP66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLNOeesh/imSCQiv99vPUbS+te//uV5zahRo+I/iLGOjo5erfv73/8e50kQb8ePH/e8Zv369b16rf379/dqHS4Lh8PKysq66vNcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJm6xHgDxtWzZMs9rJk2a1KvX+vTTTz2vueeeezyvue+++zyvmT17tuc1knT//fd7XnPs2DHPawoKCjyv6Uv/+9//PK/5/PPPPa/Jz8/3vKY3jh492qt13Iw0sbgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDPSFFNTU9Mna3qrurq6T17njjvu6NW6e++91/OaxsZGz2umTp3qeU1fOn/+vOc1//znPz2v6c0NbbOzsz2vaWlp8bwGiccVEADABAECAJjwHKA9e/bo4YcfVjAYVFpamrZv3x7zvHNOL7zwgvLz8zV48GCVlJToyJEj8ZoXAJAiPAeos7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b968Xn1NGQCQujy/CaGsrExlZWU9Puec04YNG/T8889r/vz5kqTXX39deXl52r59uxYtWnRj0wIAUkZcvwfU2tqqtrY2lZSURB/z+/0qKipSfX19j2u6uroUiURiNgBA6otrgNra2iRJeXl5MY/n5eVFn/u2qqoq+f3+6FZQUBDPkQAA/ZT5u+AqKysVDoej27Fjx6xHAgD0gbgGKBAISJLa29tjHm9vb48+920+n09ZWVkxGwAg9cU1QIWFhQoEAjE/WR+JRLRv3z4VFxfH86UAAEnO87vgzp49q+bm5ujHra2tOnjwoLKzszVixAitXr1av/71r3XXXXepsLBQa9asUTAY1IIFC+I5NwAgyXkO0P79+/XAAw9EP66oqJAkLV68WFu2bNGzzz6rzs5OLV++XGfOnNGMGTNUXV2tQYMGxW9qAEDSS3POOeshvikSicjv91uPAcCj8vJyz2veeecdz2sOHz7sec03/9HsxZdfftmrdbgsHA5f8/v65u+CAwDcnAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC869jAJD6cnNzPa959dVXPa9JT/f+b+B169Z5XsNdrfsnroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBTAFUKhkOc1w4YN87zmv//9r+c1TU1Nntegf+IKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IgRQ2ffr0Xq37xS9+EedJerZgwQLPaw4fPhz/QWCCKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwVS2EMPPdSrdQMHDvS8pqamxvOa+vp6z2uQOrgCAgCYIEAAABOeA7Rnzx49/PDDCgaDSktL0/bt22OeX7JkidLS0mK20tLSeM0LAEgRngPU2dmpyZMna+PGjVfdp7S0VCdPnoxub7755g0NCQBIPZ7fhFBWVqaysrJr7uPz+RQIBHo9FAAg9SXke0C1tbXKzc3V2LFjtXLlSp0+ffqq+3Z1dSkSicRsAIDUF/cAlZaW6vXXX1dNTY1++9vfqq6uTmVlZbp06VKP+1dVVcnv90e3goKCeI8EAOiH4v5zQIsWLYr+eeLEiZo0aZLGjBmj2tpazZkz54r9KysrVVFREf04EokQIQC4CST8bdijR49WTk6Ompube3ze5/MpKysrZgMApL6EB+j48eM6ffq08vPzE/1SAIAk4vlLcGfPno25mmltbdXBgweVnZ2t7OxsvfTSSyovL1cgEFBLS4ueffZZ3XnnnZo3b15cBwcAJDfPAdq/f78eeOCB6Mdff/9m8eLF2rRpkw4dOqQ//elPOnPmjILBoObOnatf/epX8vl88ZsaAJD00pxzznqIb4pEIvL7/dZjAP3O4MGDPa/Zu3dvr15r/Pjxntc8+OCDntd89NFHntcgeYTD4Wt+X597wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8lN4DEeOaZZzyv+f73v9+r16qurva8hjtbwyuugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFDDwox/9yPOaNWvWeF4TiUQ8r5GkdevW9Wod4AVXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCtygoUOHel7zyiuveF4zYMAAz2v+/Oc/e14jSQ0NDb1aB3jBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQLf0JsbflZXV3teU1hY6HlNS0uL5zVr1qzxvAboK1wBAQBMECAAgAlPAaqqqtLUqVOVmZmp3NxcLViwQE1NTTH7nD9/XqFQSEOHDtXtt9+u8vJytbe3x3VoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2Rvd56qmn9P777+vdd99VXV2dTpw4oUcffTTugwMAkpunNyF8+5utW7ZsUW5urhobGzVr1iyFw2H98Y9/1NatW/Xggw9KkjZv3qx77rlHDQ0Nuv/+++M3OQAgqd3Q94DC4bAkKTs7W5LU2NioixcvqqSkJLrPuHHjNGLECNXX1/f4Obq6uhSJRGI2AEDq63WAuru7tXr1ak2fPl0TJkyQJLW1tSkjI0NDhgyJ2TcvL09tbW09fp6qqir5/f7oVlBQ0NuRAABJpNcBCoVCOnz4sN56660bGqCyslLhcDi6HTt27IY+HwAgOfTqB1FXrVqlnTt3as+ePRo+fHj08UAgoAsXLujMmTMxV0Ht7e0KBAI9fi6fzyefz9ebMQAASczTFZBzTqtWrdK2bdu0e/fuK36ae8qUKRo4cKBqamqijzU1Neno0aMqLi6Oz8QAgJTg6QooFApp69at2rFjhzIzM6Pf1/H7/Ro8eLD8fr+WLl2qiooKZWdnKysrS08++aSKi4t5BxwAIIanAG3atEmSNHv27JjHN2/erCVLlkiSfv/73ys9PV3l5eXq6urSvHnz9Oqrr8ZlWABA6khzzjnrIb4pEonI7/dbj4Gb1N133+15zWeffZaASa40f/58z2vef//9BEwCfDfhcFhZWVlXfZ57wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEr34jKtDfjRw5slfr/vKXv8R5kp4988wzntfs3LkzAZMAdrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSpKTly5f3at2IESPiPEnP6urqPK9xziVgEsAOV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRop+b8aMGZ7XPPnkkwmYBEA8cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTo92bOnOl5ze23356ASXrW0tLiec3Zs2cTMAmQXLgCAgCYIEAAABOeAlRVVaWpU6cqMzNTubm5WrBggZqammL2mT17ttLS0mK2FStWxHVoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2xuy3bNkynTx5MrqtX78+rkMDAJKfpzchVFdXx3y8ZcsW5ebmqrGxUbNmzYo+fuuttyoQCMRnQgBASrqh7wGFw2FJUnZ2dszjb7zxhnJycjRhwgRVVlbq3LlzV/0cXV1dikQiMRsAIPX1+m3Y3d3dWr16taZPn64JEyZEH3/88cc1cuRIBYNBHTp0SM8995yampr03nvv9fh5qqqq9NJLL/V2DABAkup1gEKhkA4fPqy9e/fGPL58+fLonydOnKj8/HzNmTNHLS0tGjNmzBWfp7KyUhUVFdGPI5GICgoKejsWACBJ9CpAq1at0s6dO7Vnzx4NHz78mvsWFRVJkpqbm3sMkM/nk8/n680YAIAk5ilAzjk9+eST2rZtm2pra1VYWHjdNQcPHpQk5efn92pAAEBq8hSgUCikrVu3aseOHcrMzFRbW5skye/3a/DgwWppadHWrVv10EMPaejQoTp06JCeeuopzZo1S5MmTUrIfwAAIDl5CtCmTZskXf5h02/avHmzlixZooyMDO3atUsbNmxQZ2enCgoKVF5erueffz5uAwMAUoPnL8FdS0FBgerq6m5oIADAzYG7YQPf8Le//c3zmjlz5nhe8+WXX3peA6QabkYKADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhIc9e7xXUfi0Qi8vv91mMAAG5QOBxWVlbWVZ/nCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJfhegfnZrOgBAL13v7/N+F6COjg7rEQAAcXC9v8/73d2wu7u7deLECWVmZiotLS3muUgkooKCAh07duyad1hNdRyHyzgOl3EcLuM4XNYfjoNzTh0dHQoGg0pPv/p1zi19ONN3kp6eruHDh19zn6ysrJv6BPsax+EyjsNlHIfLOA6XWR+H7/Jrdfrdl+AAADcHAgQAMJFUAfL5fFq7dq18Pp/1KKY4DpdxHC7jOFzGcbgsmY5Dv3sTAgDg5pBUV0AAgNRBgAAAJggQAMAEAQIAmEiaAG3cuFGjRo3SoEGDVFRUpI8//th6pD734osvKi0tLWYbN26c9VgJt2fPHj388MMKBoNKS0vT9u3bY553zumFF15Qfn6+Bg8erJKSEh05csRm2AS63nFYsmTJFedHaWmpzbAJUlVVpalTpyozM1O5ublasGCBmpqaYvY5f/68QqGQhg4dqttvv13l5eVqb283mjgxvstxmD179hXnw4oVK4wm7llSBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUKevR+tz48eN18uTJ6LZ3717rkRKus7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b948nT9/vo8nTazrHQdJKi0tjTk/3nzzzT6cMPHq6uoUCoXU0NCgDz74QBcvXtTcuXPV2dkZ3eepp57S+++/r3fffVd1dXU6ceKEHn30UcOp4++7HAdJWrZsWcz5sH79eqOJr8IlgWnTprlQKBT9+NKlSy4YDLqqqirDqfre2rVr3eTJk63HMCXJbdu2Lfpxd3e3CwQC7ne/+130sTNnzjifz+fefPNNgwn7xrePg3POLV682M2fP99kHiunTp1yklxdXZ1z7vL/+4EDB7p33303us+nn37qJLn6+nqrMRPu28fBOed++MMfup/97Gd2Q30H/f4K6MKFC2psbFRJSUn0sfT0dJWUlKi+vt5wMhtHjhxRMBjU6NGj9cQTT+jo0aPWI5lqbW1VW1tbzPnh9/tVVFR0U54ftbW1ys3N1dixY7Vy5UqdPn3aeqSECofDkqTs7GxJUmNjoy5evBhzPowbN04jRoxI6fPh28fha2+88YZycnI0YcIEVVZW6ty5cxbjXVW/uxnpt33xxRe6dOmS8vLyYh7Py8vTZ599ZjSVjaKiIm3ZskVjx47VyZMn9dJLL2nmzJk6fPiwMjMzrccz0dbWJkk9nh9fP3ezKC0t1aOPPqrCwkK1tLTol7/8pcrKylRfX68BAwZYjxd33d3dWr16taZPn64JEyZIunw+ZGRkaMiQITH7pvL50NNxkKTHH39cI0eOVDAY1KFDh/Tcc8+pqalJ7733nuG0sfp9gPD/ysrKon+eNGmSioqKNHLkSL3zzjtaunSp4WToDxYtWhT988SJEzVp0iSNGTNGtbW1mjNnjuFkiREKhXT48OGb4vug13K147B8+fLonydOnKj8/HzNmTNHLS0tGjNmTF+P2aN+/yW4nJwcDRgw4Ip3sbS3tysQCBhN1T8MGTJEd999t5qbm61HMfP1OcD5caXRo0crJycnJc+PVatWaefOnfrwww9jfn1LIBDQhQsXdObMmZj9U/V8uNpx6ElRUZEk9avzod8HKCMjQ1OmTFFNTU30se7ubtXU1Ki4uNhwMntnz55VS0uL8vPzrUcxU1hYqEAgEHN+RCIR7du376Y/P44fP67Tp0+n1PnhnNOqVau0bds27d69W4WFhTHPT5kyRQMHDow5H5qamnT06NGUOh+udxx6cvDgQUnqX+eD9bsgvou33nrL+Xw+t2XLFvePf/zDLV++3A0ZMsS1tbVZj9anfv7zn7va2lrX2trq/vrXv7qSkhKXk5PjTp06ZT1aQnV0dLgDBw64AwcOOEnu5ZdfdgcOHHD/+c9/nHPO/eY3v3FDhgxxO3bscIcOHXLz5893hYWF7quvvjKePL6udRw6Ojrc008/7err611ra6vbtWuXu++++9xdd93lzp8/bz163KxcudL5/X5XW1vrTp48Gd3OnTsX3WfFihVuxIgRbvfu3W7//v2uuLjYFRcXG04df9c7Ds3NzW7dunVu//79rrW11e3YscONHj3azZo1y3jyWEkRIOec+8Mf/uBGjBjhMjIy3LRp01xDQ4P1SH1u4cKFLj8/32VkZLjvfe97buHCha65udl6rIT78MMPnaQrtsWLFzvnLr8Ve82aNS4vL8/5fD43Z84c19TUZDt0AlzrOJw7d87NnTvXDRs2zA0cONCNHDnSLVu2LOX+kdbTf78kt3nz5ug+X331lfvpT3/q7rjjDnfrrbe6Rx55xJ08edJu6AS43nE4evSomzVrlsvOznY+n8/deeed7plnnnHhcNh28G/h1zEAAEz0++8BAQBSEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABg4v8AjVqFRqQZEfIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측할 때 먼저 axis = 1 축에서 max 함수로 확률이 가장 높은 클래스를 먼저 계산한다. max 함수는 sample_data에서 샘플마다 클래스의 확률을 저장한 리스트와 각 샘플에 대한 클래스 레이블 리스트를 출력한다. 따라서 인덱스 [1]을 사용해 두 번째 리스트를 선택할 수 있다.  \n",
        "또한 sample_data에서 첫 번째 샘플만 보려면 인덱스 [0]을 사용해 첫 번째 클래스 레이블을 선택한다."
      ],
      "metadata": {
        "id": "zfjK2YQNMi9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model prediction is : {model(sample_data).data.max(1)[1][0]}\")\n",
        "print(f\"Ground truth is : {sample_targets[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWLRbxXqMTqr",
        "outputId": "0d03a44d-e2f8-4aa6-dacf-a7aa635cb02a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model prediction is : 7\n",
            "Ground truth is : 7\n"
          ]
        }
      ]
    }
  ]
}